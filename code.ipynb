{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh_zQ8ttbdnx"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Libraries\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Main Analysis Script\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Import ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Import ensemble methods\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Import for handling imbalanced data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('water_potability.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: water_potability.csv not found. Please ensure the file is uploaded to the Colab session.\")\n",
        "    exit()\n",
        "\n",
        "# ---------------------------------\n",
        "# 1. Raw Data & 2. Exploratory Data Analysis (EDA)\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 1. Raw Data ---\")\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Information:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n--- 2. Exploratory Data Analysis (EDA) ---\")\n",
        "print(\"\\nChecking for Null/Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df_imputed.isnull().sum())\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(df_imputed.describe())\n",
        "\n",
        "print(\"\\nGenerating visualizations...\")\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='Potability', data=df_imputed)\n",
        "plt.title('Distribution of Water Potability')\n",
        "plt.xlabel('Potability (0 = Not Potable, 1 = Potable)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "df_imputed.hist(figsize=(15, 12), bins=20)\n",
        "plt.suptitle('Histograms of All Features')\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df_imputed.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Features')\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------\n",
        "# 3. Train-Test Split\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 3. Train-Test Split ---\")\n",
        "X = df_imputed.drop('Potability', axis=1)\n",
        "y = df_imputed['Potability']\n",
        "\n",
        "potability_counts = y.value_counts()\n",
        "print(f\"Potability distribution:\\n{potability_counts}\")\n",
        "if abs(potability_counts[0] - potability_counts[1]) / len(y) > 0.1:\n",
        "    print(\"\\nDataset is imbalanced. Applying SMOTE for upsampling.\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X, y = smote.fit_resample(X, y)\n",
        "    print(f\"New distribution after SMOTE:\\n{y.value_counts()}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ---------------------------------\n",
        "# 4. Preprocessing and Scaling\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 4. Preprocessing and Scaling ---\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "print(\"Data has been scaled using StandardScaler.\")\n",
        "\n",
        "# ---------------------------------\n",
        "# 6. ML Algorithms\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 6. Training ML Algorithms ---\")\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else [0]*len(y_test)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'AUC-ROC': roc_auc_score(y_test, y_pred_proba) if hasattr(model, \"predict_proba\") else 'N/A',\n",
        "        'Model': model\n",
        "    }\n",
        "\n",
        "# ---------------------------------\n",
        "# 7. Hyperparameter Tuning (Example on Random Forest)\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 7. Hyperparameter Tuning (Example on Random Forest) ---\")\n",
        "param_grid_rf = { 'n_estimators': [100, 200], 'max_depth': [10, 20, None] }\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "grid_search_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "models['Tuned Random Forest'] = best_rf\n",
        "\n",
        "y_pred_tuned_rf = best_rf.predict(X_test_scaled)\n",
        "y_pred_proba_tuned_rf = best_rf.predict_proba(X_test_scaled)[:, 1]\n",
        "results['Tuned Random Forest'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_tuned_rf), 'Precision': precision_score(y_test, y_pred_tuned_rf), 'Recall': recall_score(y_test, y_pred_tuned_rf), 'F1-Score': f1_score(y_test, y_pred_tuned_rf), 'AUC-ROC': roc_auc_score(y_test, y_pred_proba_tuned_rf), 'Model': best_rf\n",
        "}\n",
        "\n",
        "# ---------------------------------\n",
        "# 8 & 10. Ensemble Technique (Voting Classifier)\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 8 & 10. Designing Ensemble Technique (Voting Classifier) ---\")\n",
        "estimators = [('lr', models['Logistic Regression']), ('rf', best_rf), ('xgb', models['XGBoost'])]\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "models['Ensemble (Voting)'] = voting_clf\n",
        "\n",
        "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
        "y_pred_proba_voting = voting_clf.predict_proba(X_test_scaled)[:, 1]\n",
        "results['Ensemble (Voting)'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_voting), 'Precision': precision_score(y_test, y_pred_voting), 'Recall': recall_score(y_test, y_pred_voting), 'F1-Score': f1_score(y_test, y_pred_voting), 'AUC-ROC': roc_auc_score(y_test, y_pred_proba_voting), 'Model': voting_clf\n",
        "}\n",
        "\n",
        "# ---------------------------------\n",
        "# 9 & 11. Model Evaluation and Comparative Analysis\n",
        "# ---------------------------------\n",
        "print(\"\\n--- 9 & 11. Model Evaluation and Comparative Analysis ---\")\n",
        "results_df = pd.DataFrame(results).T.drop(columns=['Model'])\n",
        "print(results_df.sort_values(by='F1-Score', ascending=False))\n",
        "\n",
        "best_model_name = results_df['F1-Score'].idxmax()\n",
        "best_model = results[best_model_name]['Model']\n",
        "\n",
        "print(f\"\\nClassification Report for the Best Model ({best_model_name}):\")\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Potable', 'Potable'], yticklabels=['Not Potable', 'Potable'])\n",
        "plt.title(f'Confusion Matrix for {best_model_name}')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, values in results.items():\n",
        "    model = values['Model']\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves for All Models')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nDW6CB2tcE89"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}